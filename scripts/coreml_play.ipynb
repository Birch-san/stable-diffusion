{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, KarrasVeScheduler\n",
    "# from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
    "from PIL import Image\n",
    "\n",
    "kve = KarrasVeScheduler(\n",
    "    sigma_max=14.6146,\n",
    "    # sigma_min=0.0936,\n",
    "    sigma_min=0.0292,\n",
    "    s_churn=0.\n",
    ")\n",
    "# lms = LMSDiscreteScheduler(\n",
    "#   beta_start=0.00085,\n",
    "#   beta_end=0.012,\n",
    "#   beta_schedule=\"scaled_linear\"\n",
    "# )\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"/Users/birch/git/stable-diffusion-v1-4\", safety_checker=None)# torch_type=torch.float16, revision=\"fp16\")\n",
    "# pipe = pipe.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "from pathlib import Path\n",
    "import torch as th\n",
    "# from types import SimpleNamespace\n",
    "from diffusers.models.unet_2d_condition import UNet2DConditionOutput\n",
    "\n",
    "def generate_coreml_model_via_awful_hacks(f, out_name):\n",
    "    from coremltools.converters.mil import Builder as mb\n",
    "    from coremltools.converters.mil.frontend.torch.torch_op_registry import register_torch_op, _TORCH_OPS_REGISTRY\n",
    "    import coremltools.converters.mil.frontend.torch.ops as cml_ops\n",
    "    orig_einsum = th.einsum\n",
    "    def fake_einsum(a, b, c):\n",
    "        if a == 'b i d, b j d -> b i j': return th.bmm(b, c.permute(0, 2, 1))\n",
    "        if a == 'b i j, b j d -> b i d': return th.bmm(b, c)\n",
    "        raise ValueError(f\"unsupported einsum {a} on {b.shape} {c.shape}\")\n",
    "    th.einsum = fake_einsum\n",
    "    if \"broadcast_to\" in _TORCH_OPS_REGISTRY: del _TORCH_OPS_REGISTRY[\"broadcast_to\"]\n",
    "    @register_torch_op\n",
    "    def broadcast_to(context, node): return cml_ops.expand(context, node)\n",
    "    if \"gelu\" in _TORCH_OPS_REGISTRY: del _TORCH_OPS_REGISTRY[\"gelu\"]\n",
    "    @register_torch_op\n",
    "    def gelu(context, node): context.add(mb.gelu(x=context[node.inputs[0]], name=node.name))\n",
    "    class Undictifier(th.nn.Module):\n",
    "        def __init__(self, m):\n",
    "            super().__init__()\n",
    "            self.m = m\n",
    "        def forward(self, *args, **kwargs): return self.m(*args, **kwargs)[\"sample\"]\n",
    "    print(\"tracing\")\n",
    "    f_trace = th.jit.trace(Undictifier(f), (th.zeros(2, 4, 64, 64), th.zeros(1), th.zeros(2, 77, 768)), strict=False, check_trace=False)\n",
    "    print(\"converting\")\n",
    "    f_coreml_fp16 = ct.convert(f_trace, \n",
    "               inputs=[ct.TensorType(shape=(2, 4, 64, 64)), ct.TensorType(shape=(1,)), ct.TensorType(shape=(2, 77, 768))],\n",
    "               convert_to=\"mlprogram\",  compute_precision=ct.precision.FLOAT16, skip_model_load=True)\n",
    "    f_coreml_fp16.save(f\"{out_name}\")\n",
    "    th.einsum = orig_einsum\n",
    "    print(\"the deed is done\")\n",
    "    \n",
    "class UNetWrapper:\n",
    "    def __init__(self, f, out_name=\"unet.mlpackage\"):\n",
    "        self.in_channels = f.in_channels\n",
    "        if not Path(out_name).exists():\n",
    "            print(\"generating coreml model\"); generate_coreml_model_via_awful_hacks(f, out_name); print(\"saved\")\n",
    "        # not only does ANE take forever to load because it recompiles each time - it then doesn't work!\n",
    "        # and NSLocalizedDescription = \"Error computing NN outputs.\"; is not helpful... GPU it is\n",
    "        print(\"loading saved coreml model\"); f_coreml_fp16 = ct.models.MLModel(out_name, compute_units=ct.ComputeUnit.CPU_AND_GPU); print(\"loaded\")\n",
    "        self.f = f_coreml_fp16\n",
    "    def __call__(self, sample, timestep, encoder_hidden_states):\n",
    "        args = {\"sample\": sample.numpy(), \"timestep\": th.tensor([timestep], dtype=th.int32).numpy(), \"input_35\": encoder_hidden_states.numpy()}\n",
    "        for v in self.f.predict(args).values():\n",
    "            return UNet2DConditionOutput(\n",
    "                sample=th.tensor(v, dtype=th.float32)\n",
    "            )\n",
    "pipe.unet = UNetWrapper(pipe.unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"masterpiece character portrait of a blonde girl, full resolution, 4k, mizuryuu kei, akihiko. yoshida, Pixiv featured, baroque scenic, by artgerm, sylvain sarrailh, rossdraws, wlop, global illumination, vaporwave\"\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(68673924)\n",
    "image: Image.Image = pipe(\n",
    "\tprompt,\n",
    "\t# guidance_scale=1.,\n",
    "\tgenerator=generator,  \n",
    "  # scheduler=lms,\n",
    "  scheduler=kve,\n",
    "  # num_inference_steps=30\n",
    "  num_inference_steps=15\n",
    ").images[0]\n",
    "\n",
    "sample_path=\"../outputs/diffusers\"\n",
    "base_count = len(os.listdir(sample_path))\n",
    "image.save(os.path.join(sample_path, f\"{base_count:05}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldmwaifu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a92dc80897b2281210963dc442dd7351ec0107b72c9edf600b7f605562bed7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
